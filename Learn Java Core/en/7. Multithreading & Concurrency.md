### **Lesson 1: Understanding Threads and Their Lifecycle**

#### **1. Concept Explanation**

##### **What is a Thread? Process vs. Thread**
*   A **process** is an instance of a computer program being executed. It has its own dedicated memory space, isolated from other processes. Think of your web browser or a text editor; each is a separate process.
*   A **thread** is the smallest unit of execution within a process. A process can have one or more threads, which are often called lightweight processes. All threads within a single process share the same memory space (heap memory), which allows them to share data easily but also introduces the risk of data corruption (race conditions).

**Analogy:** A **process** is like a restaurant. It has its own kitchen, ingredients, and staff (memory, resources). A **thread** is like a chef in that restaurant. A single-chef restaurant (single-threaded process) can only do one thing at a time. A multi-chef restaurant (multi-threaded process) can prepare multiple dishes concurrently, increasing throughput. All chefs share the same kitchen and ingredients (shared memory).

##### **Thread Lifecycle (States)**
A Java thread can exist in one of six states, defined in the `Thread.State` enum. Understanding these states is crucial for debugging and analyzing concurrent applications.

```
                  start()
      +-------+  ---------> +-----------+
      |  NEW  |             | RUNNABLE  | <--------------------+
      +-------+  <--------- +-----------+                      |
                  (finished)     |   ^                         |
                                 |   | (yield, or OS schedules)  |
      +------------+ <-----------+   |                         |
      | TERMINATED |             v   | (I/O, synchronized block) |
      +------------+      +-----------+                         |
                          |  BLOCKED  | ------------------------+
                          +-----------+   (lock acquired)
                                 |
           (wait(), join(), LockSupport.park())
                                 v
      +-----------+ <------- +-----------+
      |  WAITING  |          |TIMED_WAITING|
      +-----------+ -------> +-----------+
       ^      (notify(),    (timeout expires,
       |       interrupt())   notify(), interrupt())
       +----------------------------+
```
*   **`NEW`**: The thread has been created but its `start()` method has not yet been called. It is not yet alive.
*   **`RUNNAB`LE**: The thread is eligible to be run by the thread scheduler. This state includes both "running" and "ready to run." A thread in the `RUNNABLE` state might be actively executing code, or it might be waiting for the OS to give it a time slice on a CPU core.
*   **`BLOCKED`**: The thread is waiting to acquire an intrinsic monitor lock (i.e., it's waiting to enter a `synchronized` block or method that another thread currently holds the lock for).
*   **`WAITING`**: The thread is in an indefinite waiting state. It is waiting for another thread to perform a specific action, such as calling `notify()` or `notifyAll()` on an object the thread is `wait()`ing on, or for a thread it has `join()`ed to terminate.
*   **`TIMED_WAITING`**: The thread is in a waiting state for a specified amount of time. It will transition back to `RUNNABLE` if the timeout expires or if it receives a `notify()`/`interrupt()`. This is the state for calls like `Thread.sleep(long)`, `wait(long)`, and `join(long)`.
*   **`TERMINATED`**: The thread has completed its execution (its `run()` method has exited) or has been otherwise terminated.

##### **Creating and Starting Threads**
1.  **Implementing `Runnable` (Preferred):**
    *   Create a class that implements the `java.lang.Runnable` interface and its `run()` method.
    *   Create an instance of this class.
    *   Create a new `Thread` object, passing the `Runnable` instance to its constructor.
    *   Call `thread.start()`.
    *   **Why is this preferred?** It separates the task (the `Runnable`) from the execution mechanism (the `Thread`), promoting better object-oriented design (favor composition over inheritance). You can also implement other interfaces or extend other classes.

2.  **Extending `Thread`:**
    *   Create a class that extends `java.lang.Thread`.
    *   Override the `run()` method.
    *   Create an instance of your subclass and call `start()`.
    *   This is less flexible because Java does not support multiple inheritance.

**`start()` vs. `run()`:** This is a classic interview question.
*   **`thread.start()`**: This is the correct way to start a new thread. It tells the JVM to create a new thread of execution and have that new thread invoke the `run()` method. It returns immediately.
*   **`thread.run()`**: This is just a normal method call. It executes the code in the `run()` method on the **current thread**, not a new one. No multithreading occurs.

##### **Joining Threads (`join()`)**
The `thread.join()` method causes the current thread to pause its execution until the thread it is joining (`thread`) completes (i.e., enters the `TERMINATED` state). This is a crucial mechanism for coordinating work between threads.

##### **Daemon vs. Non-Daemon (User) Threads**
*   **Non-Daemon (User) Threads:** These are the default. The JVM will **not** exit as long as at least one non-daemon thread is still alive, even if the `main` thread has finished.
*   **Daemon Threads:** These are low-priority threads that provide background services. The JVM **will** exit if the only threads left running are daemon threads. Their `run()` methods might not complete, and `finally` blocks are not guaranteed to be executed. Use `thread.setDaemon(true)` to mark a thread as a daemon *before* starting it.

---

#### **2. Example Code Snippet**

```java
// Method 1: Implementing Runnable (Preferred)
class Task implements Runnable {
    private final String name;

    public Task(String name) { this.name = name; }

    @Override
    public void run() {
        for (int i = 1; i <= 5; i++) {
            System.out.println("Runnable Task '" + name + "' running, count: " + i);
            try {
                Thread.sleep(100); // Enters TIMED_WAITING state
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

// Method 2: Extending Thread
class Worker extends Thread {
    public Worker(String name) { super(name); }

    @Override
    public void run() {
        for (int i = 1; i <= 5; i++) {
            System.out.println("Thread '" + getName() + "' running, count: " + i);
        }
    }
}

public class ThreadCreationDemo {
    public static void main(String[] args) {
        System.out.println("Main thread started.");

        // Create thread using Runnable
        Thread t1 = new Thread(new Task("A"));

        // Create thread using Thread extension
        Worker t2 = new Worker("B");

        // Start both threads
        t1.start(); // t1 enters RUNNABLE state
        t2.start(); // t2 enters RUNNABLE state

        try {
            // main thread WAITS for t1 and t2 to finish
            t1.join();
            t2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        System.out.println("Main thread finished after t1 and t2 completed.");
    }
}
```

---

#### **3. Mini Exercise**
Write a program that calculates the sum of numbers from 1 to 1,000,000 in a separate thread.
1.  Create a `Runnable` class called `SumCalculator` that takes the upper limit (1,000,000) in its constructor.
2.  The `run()` method should perform the summation.
3.  The `SumCalculator` class should have a `getSum()` method to retrieve the result after the calculation is done. (Note: You'll need to think about how to make the `sum` variable visible to the main thread. A simple public getter will work for this exercise, but we'll see why this can be problematic later).
4.  In the `main` method, create and start the thread.
5.  `join()` the thread to wait for it to finish.
6.  After the thread has terminated, get the sum and print it.

---

#### **4. Quiz Question**

**Question:** What is the fundamental difference between invoking `myThread.start()` and `myThread.run()`?

A) `start()` executes the `run()` method in a new thread, while `run()` executes it in the current thread.
B) `start()` is used for daemon threads, while `run()` is used for user threads.
C) `start()` puts the thread in the `BLOCKED` state, while `run()` puts it in the `RUNNABLE` state.
D) There is no difference; `start()` is just a synonym for `run()`.

*(Scroll down for the answer)*

...

**Answer:** A) `start()` executes the `run()` method in a new thread, while `run()` executes it in the current thread. `start()` is the method that actually triggers the creation of a new, concurrent path of execution. Calling `run()` directly is just a simple method invocation.

### **Lesson 2: Synchronization and Race Conditions**

#### **1. Concept Explanation**

##### **The Problem: Shared Mutable State**
The power of multithreading comes from threads sharing the same memory space, but this is also its greatest danger. When two or more threads have access to the same object (shared state), and at least one of those threads can change the state of that object (mutable state), you have a recipe for disaster.

A **race condition** is a bug that occurs when the outcome of a computation depends on the unpredictable timing or interleaving of operations from multiple threads. The threads "race" to access and modify the shared state, and the result is chaos.

The most common type of race condition is the **check-then-act** pattern:
1.  **Thread A** checks a condition (e.g., "is the value less than 10?").
2.  The thread scheduler pauses Thread A and switches to **Thread B**.
3.  **Thread B** modifies the value (e.g., increments it to 10).
4.  The scheduler switches back to **Thread A**.
5.  **Thread A**, unaware that the value has changed, proceeds to *act* based on its old, stale information (e.g., it also increments the value, making it 11, which might be an invalid state).

##### **Atomicity**
An operation is **atomic** if it is performed as a single, indivisible unit. No other thread can see the operation in a halfway-complete state. In Java, reading or writing a reference is atomic. Reading or writing most primitives (`int`, `boolean`, etc.) is atomic. However, `long` and `double` are 64-bit values, and on some 32-bit JVMs, their reads/writes might not be atomic (this is less of an issue on modern 64-bit systems).

Crucially, compound operations like `count++` are **not atomic**. They are a sequence of three separate operations:
1.  Read the current value of `count`.
2.  Increment the read value.
3.  Write the new value back to `count`.
    A thread can be paused between any of these steps, leading to a race condition.

##### **The Solution: Synchronization and Intrinsic Locks**
Synchronization is the mechanism for enforcing controlled access to shared resources in a concurrent environment. Java's primary synchronization tool is the `synchronized` keyword.

Every single object in Java has an **intrinsic lock** (also called a monitor lock or a monitor). This lock acts like a token that only one thread can hold at a time.

1.  **Synchronized Methods:** When you declare a method as `synchronized`, a thread must acquire the intrinsic lock of the **object instance** (`this`) before it can execute the method. If another thread tries to call *any* synchronized method on the *same object instance*, it will be blocked until the first thread releases the lock by exiting the method.
    *   For `static synchronized` methods, the lock is on the `Class` object itself, not an instance.

2.  **Synchronized Blocks:** This provides more granular control. You specify which object's lock you want to acquire.
    `synchronized (someObject) { ... }`
    A thread must acquire the lock on `someObject` before executing the code inside the block. This is more flexible because you can use a dedicated lock object or synchronize on a different object than `this`.

**Reentrancy:** Java's intrinsic locks are **reentrant**. This means that if a thread already holds the lock on an object, it can re-acquire the same lock without blocking itself. This is important for preventing self-deadlock, for example, when a synchronized method calls another synchronized method on the same object. The JVM keeps a count of how many times the lock has been acquired by the thread. The lock is only released when the count returns to zero.

---

#### **2. Example Code Snippet: Race Condition and Synchronization**

##### **The Problem: Race Condition**
This code will almost never produce the expected result of 20,000 because of the race condition on `count++`.

```java
class UnsafeCounter {
    private int count = 0;

    public void increment() {
        count++; // Not an atomic operation
    }

    public int getCount() {
        return count;
    }
}

public class RaceConditionDemo {
    public static void main(String[] args) throws InterruptedException {
        UnsafeCounter counter = new UnsafeCounter();
        Runnable task = () -> {
            for (int i = 0; i < 10000; i++) {
                counter.increment();
            }
        };

        Thread t1 = new Thread(task);
        Thread t2 = new Thread(task);

        t1.start();
        t2.start();

        t1.join();
        t2.join();

        // The final count will be unpredictable and less than 20,000.
        System.out.println("Final count (unsafe): " + counter.getCount());
    }
}
```

##### **The Solution: Synchronization**
By adding the `synchronized` keyword, we ensure that the `increment` method is atomic.

```java
class SafeCounter {
    private int count = 0;

    // Only one thread can execute this method on the same instance at a time.
    public synchronized void increment() {
        count++;
    }

    public int getCount() {
        return count;
    }
}

public class SynchronizationDemo {
    public static void main(String[] args) throws InterruptedException {
        SafeCounter counter = new SafeCounter();
        Runnable task = () -> {
            for (int i = 0; i < 10000; i++) {
                counter.increment();
            }
        };

        Thread t1 = new Thread(task);
        Thread t2 = new Thread(task);

        t1.start();
        t2.start();

        t1.join();
        t2.join();

        // The final count will always be exactly 20,000.
        System.out.println("Final count (safe): " + counter.getCount());
    }
}
```

---

#### **3. Mini Exercise**

You have a `BankAccount` class with `deposit(double amount)` and `withdraw(double amount)` methods. The account balance is stored in a `private double balance` field.
1.  Implement the class without any synchronization.
2.  Create a scenario with two threads: one thread continuously deposits $10 in a loop (1000 times), and the other continuously withdraws $10 in a loop (1000 times).
3.  Start with a balance of $500. After both threads finish, the final balance should still be $500, but because of race conditions, it likely won't be.
4.  Your task is to use the `synchronized` keyword on the `deposit` and `withdraw` methods to make the `BankAccount` class thread-safe and ensure the final balance is correct.

---

#### **4. Quiz Question**

**Question:** A `static` method is declared as `synchronized`. Which object's intrinsic lock must a thread acquire to execute this method?

A) The `this` object instance on which the method was called.
B) A new lock object created specifically for this method call.
C) The `Class` object corresponding to the class where the method is defined.
D) `static` methods cannot be synchronized.

*(Scroll down for the answer)*

...

**Answer:** C) The `Class` object corresponding to the class where the method is defined. Since a `static` method is not associated with any specific instance (`this`), the lock is acquired on the `java.lang.Class` object for that class. This means only one thread can be executing *any* static synchronized method in that class at a time.

### **Lesson 3: The Java Memory Model and `volatile`**

#### **1. Concept Explanation**

Synchronization is about more than just mutual exclusion (atomicity); it's also about ensuring that changes made by one thread are visible to others. This problem of **visibility** is governed by a complex set of rules called the **Java Memory Model (JMM)**.

##### **The Problem: Threads Have Their Own Caches**
Modern computer architectures are complex. To improve performance, each CPU core has its own set of caches that sit between the core and the main memory (RAM). When a thread running on Core A reads a variable from main memory, it may copy that value into its local cache. When it modifies the variable, it might only update the value in its local cache.

This leads to a major problem:
1.  **Thread A** on **Core A** reads `flag = false` from main memory into its cache.
2.  **Thread B** on **Core B** reads `flag = false` from main memory into its cache.
3.  **Thread A** updates `flag = true`. This change might only be written to **Core A's cache**. Main memory and Core B's cache still see `flag` as `false`.
4.  **Thread B** checks the value of `flag`. It reads from its own cache and sees `false`, even though Thread A changed it. Thread B is working with stale data.

**The JMM** is a specification that defines the guarantees the JVM makes about when a write to a variable by one thread is guaranteed to be visible to a subsequent read of that same variable by another thread. It defines the "happens-before" relationship.

##### **The `happens-before` Relationship**
If action A *happens-before* action B, then the results of A are guaranteed to be visible to and ordered before B. The JMM defines several key `happens-before` rules:
1.  **Program Order Rule:** Actions within a single thread happen in the order they appear in the code.
2.  **Monitor Lock Rule:** An *unlock* on a monitor lock (exiting a `synchronized` block) *happens-before* every subsequent *lock* on that same monitor.
3.  **`volatile` Variable Rule:** A *write* to a `volatile` variable *happens-before* every subsequent *read* of that same `volatile` variable.
4.  **Thread Start Rule:** A call to `Thread.start()` *happens-before* any action in the new thread.
5.  **Thread Join Rule:** All actions in a thread *happen-before* another thread successfully returns from a `join()` on it.

##### **The Role of `synchronized` in Memory Visibility**
The `synchronized` keyword solves both atomicity and visibility problems.
*   When a thread **enters** a `synchronized` block, it invalidates its local cache and is forced to read the latest values of shared variables from main memory.
*   When a thread **exits** a `synchronized` block, it flushes any changes it made to shared variables from its local cache back to main memory.

This is what the "Monitor Lock Rule" guarantees. The unlock (exit) by Thread A flushes its changes, and the lock (entry) by Thread B forces a fresh read, ensuring Thread B sees Thread A's work.

##### **The `volatile` Keyword: A Weaker Form of Synchronization**
The `volatile` keyword is a field modifier that provides a guarantee of **visibility** and **ordering**, but **not atomicity**.

When you declare a field as `volatile`:
1.  **Visibility:** Any write to that `volatile` field is guaranteed to be flushed to main memory immediately. Any read of that `volatile` field is guaranteed to be read directly from main memory. This solves the stale cache problem.
2.  **Ordering:** It prevents the compiler and CPU from reordering instructions involving the `volatile` variable in a way that would violate the happens-before relationship. It acts as a "memory barrier."

**`volatile` vs. `synchronized`:**
*   Use `synchronized` when you need to protect a compound action (like `count++`) and ensure **atomicity**. It's a lock-based, mutual exclusion mechanism.
*   Use `volatile` when you have a simple flag or variable that is being written by one thread and read by others, and you only need to ensure **visibility**. `volatile` is much lighter weight than `synchronized` as it does not involve locking and blocking threads.

**A classic use case for `volatile` is a status flag to terminate a thread.**

---

#### **2. Example Code Snippet: `volatile` for Visibility**

##### **The Problem: A Stale Flag**
Without `volatile`, the `readerThread` might cache the value of `flag` as `false` and never see the change made by the `main` thread, leading to an infinite loop. This is not guaranteed to happen, but it's a possibility allowed by the JMM.

```java
class StaleWorker {
    // Without volatile, the change to 'flag' might not be visible.
    private boolean flag = true;

    public void work() {
        while (flag) {
            // ... do some work ...
        }
        System.out.println("StaleWorker: I've been told to stop.");
    }

    public void stopWorking() {
        this.flag = false;
    }
}
```

##### **The Solution: Using `volatile`**
By making `flag` volatile, we guarantee that any change made by one thread is immediately visible to any other thread that reads it.

```java
class VolatileWorker {
    // The volatile keyword guarantees visibility.
    private volatile boolean flag = true;

    public void work() {
        while (flag) {
            // The read of 'flag' will always come from main memory.
        }
        System.out.println("VolatileWorker: I've been told to stop.");
    }

    public void stopWorking() {
        // The write to 'flag' will be flushed to main memory immediately.
        this.flag = false;
        System.out.println("Main thread set flag to false.");
    }
}

public class VolatileDemo {
    public static void main(String[] args) throws InterruptedException {
        VolatileWorker worker = new VolatileWorker();
        Thread workerThread = new Thread(worker::work);

        workerThread.start();

        // Let the worker thread run for a bit
        Thread.sleep(100);

        // Tell the worker to stop
        worker.stopWorking();

        // Wait for the worker thread to terminate
        workerThread.join();
        System.out.println("Worker thread has terminated.");
    }
}
```

---

#### **3. Mini Exercise**
Create a class `TaskRunner` with two methods: `executeTask()` and `getLatestResult()`.
1.  It should have two fields: `private int result` and `private volatile boolean ready`. Initialize `result = 0` and `ready = false`.
2.  The `executeTask()` method will be called by a "worker" thread. It should perform a simple calculation (e.g., set `result = 42`) and then, as the very last step, set `ready = true`.
3.  The `getLatestResult()` method will be called by a "main" thread. It should loop (`while (!ready)`) until the `ready` flag becomes true. This is a form of "busy-waiting" (which we'll see better ways to handle later). Once `ready` is true, it should return the `result`.
4.  Explain why `ready` must be `volatile`. (Hint: Think about the happens-before rule and instruction reordering. What if the compiler reordered the code so `ready = true` was set *before* `result = 42`?)

---

#### **4. Quiz Question**

**Question:** You have a shared counter variable `private int count = 0;` that is incremented by multiple threads using the `count++;` operation. Which keyword is the correct choice to make this operation thread-safe?

A) `volatile`, because it ensures the latest value of `count` is always read from main memory.
B) `final`, because it prevents the `count` variable from being reassigned.
C) `synchronized`, because `count++` is a compound operation (read-modify-write) that must be atomic.
D) `static`, because it makes the variable shared among all instances.

*(Scroll down for the answer)*

...

**Answer:** C) `synchronized`. `volatile` is not enough here. While `volatile` would ensure that each thread sees the latest value of `count`, it does **not** make the `count++` operation atomic. Two threads could still read the same value (e.g., 5), both increment it to 6, and both write 6 back, losing an increment. `synchronized` is required to lock the entire read-modify-write sequence, ensuring atomicity.

### **Lesson 4: Thread Communication (`wait()`, `notify()`, `notifyAll()`)**

#### **1. Concept Explanation**

While `volatile` is good for one-way communication (signaling), more complex coordination between threads requires a mechanism for one thread to pause its execution until another thread signals that some condition has been met. The classic mechanism for this in Java is the trio of methods: `wait()`, `notify()`, and `notifyAll()`.

These methods are defined in the `java.lang.Object` class, which means every single object in Java can act as a condition queue.

##### **The Intrinsic Lock and the "Condition Queue"**
Every Java object has two related pieces of machinery for concurrency:
1.  **An Intrinsic Lock (or Monitor):** This is what the `synchronized` keyword uses for mutual exclusion. Only one thread can "own" the lock at a time.
2.  **A Condition Queue (or Wait Set):** This is an invisible set of threads associated with the object. These are threads that have called `wait()` on the object and are now paused.

##### **How `wait()`, `notify()`, and `notifyAll()` Work**

*   **`wait()`:**
    1.  A thread **must first own the intrinsic lock** of an object to call `wait()` on it. If it doesn't, it will throw an `IllegalMonitorStateException`. This means `wait()` must be called from within a `synchronized` block or method.
    2.  When a thread calls `object.wait()`, it **atomically releases the lock** on `object` and enters the `WAITING` state.
    3.  It is then placed in the object's condition queue and remains dormant until another thread calls `notify()` or `notifyAll()` on the *same object*.
    4.  When the waiting thread is awakened, it does **not** immediately resume execution. It must first **re-acquire the lock** on the object. It will be moved from the `WAITING` state to the `BLOCKED` state until the lock becomes available.

*   **`notify()`:**
    1.  A thread **must also own the intrinsic lock** of an object to call `notify()` on it.
    2.  It wakes up a **single, arbitrarily chosen** thread from the set of threads waiting on that object's condition queue.
    3.  The awakened thread will then attempt to re-acquire the lock. The notifying thread does not release the lock until it exits its `synchronized` block.

*   **`notifyAll()`:**
    1.  Same as `notify()`, but it wakes up **all** threads waiting on the object's condition queue.
    2.  All awakened threads will then compete to acquire the lock. Only one will win at a time, but eventually, all will get a chance to run.
    *   **Best Practice:** **Always prefer `notifyAll()` over `notify()`**. Using `notify()` is a risky optimization. You might accidentally wake up the wrong type of thread (if multiple conditions are being waited on), or you might fail to wake up a thread that needs to run, leading to deadlocks. `notifyAll()` is safer and more robust.

##### **Spurious Wakeups and The `while` Loop**
For complex reasons related to OS thread scheduling, it is possible for a waiting thread to wake up *without* having been notified (a "spurious wakeup"). Because of this, the Java specification mandates that `wait()` must **always** be called inside a `while` loop that re-checks the condition it was waiting for.

**The Canonical `wait()` Loop:**
```java
synchronized (lockObject) {
    while (!conditionIsMet) { // DO NOT use an 'if' statement here!
        lockObject.wait();
    }
    // Proceed, the condition is now guaranteed to be met.
}
```
This loop protects against spurious wakeups. If the thread wakes up for any reason and the condition is still not true, it will simply call `wait()` again and go back to sleep.

---

#### **2. Example Code Snippet: The Producer-Consumer Problem**

This is the classic problem that `wait()` and `notifyAll()` are designed to solve. A "producer" thread creates items and adds them to a shared buffer, and a "consumer" thread takes items from the buffer.

```java
import java.util.LinkedList;
import java.util.Queue;

// This class represents the shared buffer
class MessageQueue {
    private final Queue<String> queue = new LinkedList<>();
    private final int capacity;

    public MessageQueue(int capacity) {
        this.capacity = capacity;
    }

    // Producer calls this method
    public synchronized void produce(String message) throws InterruptedException {
        // Wait while the queue is full
        while (queue.size() == capacity) {
            System.out.println("Queue is full, producer is waiting...");
            wait(); // Releases the lock and waits
        }
        queue.add(message);
        System.out.println("Produced: " + message);
        notifyAll(); // Notify any waiting consumers that an item is available
    }

    // Consumer calls this method
    public synchronized String consume() throws InterruptedException {
        // Wait while the queue is empty
        while (queue.isEmpty()) {
            System.out.println("Queue is empty, consumer is waiting...");
            wait(); // Releases the lock and waits
        }
        String message = queue.poll();
        System.out.println("Consumed: " + message);
        notifyAll(); // Notify any waiting producers that space is available
        return message;
    }
}

public class ProducerConsumerDemo {
    public static void main(String[] args) {
        MessageQueue queue = new MessageQueue(2); // A small capacity to see blocking

        Thread producer = new Thread(() -> {
            try {
                for (int i = 0; i < 5; i++) {
                    queue.produce("Message " + i);
                    Thread.sleep(500);
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        });

        Thread consumer = new Thread(() -> {
            try {
                for (int i = 0; i < 5; i++) {
                    queue.consume();
                    Thread.sleep(1000);
                }
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        });

        producer.start();
        consumer.start();
    }
}
```

---

#### **3. Mini Exercise**

Create a `CountDownLatch` simulation using `wait()` and `notifyAll()`. A countdown latch is a mechanism that allows one or more threads to wait until a set of operations being performed in other threads completes.
1.  Create a class `MyLatch` with a constructor that takes a `count`.
2.  It should have a `private int count` field.
3.  Implement a `countDown()` method. This method should be `synchronized`, decrement the count, and if the count reaches zero, it should call `notifyAll()`.
4.  Implement an `await()` method. This method should be `synchronized`. Inside a `while` loop, it should check if the count is greater than zero. If it is, it should call `wait()`.
5.  In `main`, create a latch with a count of 3. Start three "worker" threads that each sleep for a random time and then call `countDown()`. The `main` thread should call `await()` immediately after starting the workers and then print "All workers have finished."

---

#### **4. Quiz Question**

**Question:** A thread calls `myObject.wait()`. Which of the following statements is **true**?

A) The thread immediately resumes execution as soon as another thread calls `myObject.notify()`.
B) The thread must own the lock on `myObject` before calling `wait()`, and it releases this lock while waiting.
C) `wait()` can only be called outside of a `synchronized` block.
D) The thread enters the `BLOCKED` state while waiting.

*(Scroll down for the answer)*

...

**Answer:** B) The thread must own the lock on `myObject` before calling `wait()`, and it releases this lock while waiting. This is the core mechanism of `wait()`. It must hold the lock to ensure the condition it's checking is stable, and it must release the lock so that other threads (like a producer) can acquire the lock to change the condition and call `notify()`. While waiting, the thread is in the `WAITING` state, not `BLOCKED`.

### **Lesson 5: The Executor Framework**

#### **1. Concept Explanation**

Manually creating, starting, and managing threads (`new Thread(...)`) is feasible for simple applications, but it becomes cumbersome and inefficient for complex, enterprise-grade systems. This approach has several drawbacks:
*   **High Overhead:** Creating a new `Thread` object is a relatively expensive operation.
*   **Resource Exhaustion:** Creating an unlimited number of threads can quickly consume system memory and CPU resources, leading to poor performance or even application crashes.
*   **Lack of Management:** There is no built-in way to easily manage the lifecycle, queuing, or statistics of manually created threads.

The **Executor Framework**, part of the `java.util.concurrent` package, solves these problems by decoupling **task submission** from **task execution**.

**Analogy:** Instead of hiring a new temporary worker (creating a `Thread`) every time you have a single task, you hire a permanent team of workers (a **thread pool**). You, the manager (your main code), simply hand tasks from a to-do list (a `BlockingQueue`) to your team leader (the `ExecutorService`). The team leader assigns tasks to available workers. This is far more efficient.

##### **Core Interfaces and Classes**

*   **`Executor`:** A simple interface with a single method, `execute(Runnable command)`. It's the most basic way to submit a task. It "fires and forgets" – you cannot get a result back.

*   **`ExecutorService`:** The most important interface. It extends `Executor` and adds methods for managing the lifecycle of the executor and for handling tasks that produce results.
    *   **`submit(Runnable task)` / `submit(Callable<T> task)`:** Submits a task for execution and returns a `Future` object, which represents the pending result of the task.
    *   **`shutdown()`:** Initiates an orderly shutdown. It stops accepting new tasks but allows previously submitted tasks to complete.
    *   **`shutdownNow()`:** Attempts to stop all actively executing tasks, halts the processing of waiting tasks, and returns a list of the tasks that were awaiting execution.
    *   **`awaitTermination(long timeout, TimeUnit unit)`:** Blocks until all tasks have completed after a shutdown request, or the timeout occurs.

*   **`Executors` (Factory Class):** A utility class that provides convenient factory methods for creating different types of pre-configured thread pools. You should generally use this for simple cases.

##### **Types of Thread Pools**

1.  **Fixed Thread Pool (`Executors.newFixedThreadPool(int nThreads)`)**
    *   **Behavior:** Creates a pool with a fixed number of threads. If all threads are busy and more tasks are submitted, the tasks are placed in an unbounded `LinkedBlockingQueue` to wait.
    *   **Use Case:** Ideal for CPU-intensive tasks where the number of threads should be close to the number of available CPU cores to avoid excessive context switching. It provides predictable resource usage.

2.  **Cached Thread Pool (`Executors.newCachedThreadPool()`)**
    *   **Behavior:** Creates a pool that grows and shrinks dynamically. It creates new threads as needed if all existing threads are busy. Threads that are idle for 60 seconds are terminated and removed from the pool.
    *   **Use Case:** Excellent for a large number of short-lived, asynchronous tasks, typically I/O-bound tasks where threads spend a lot of time waiting.
    *   **Risk:** Can lead to resource exhaustion if a huge number of tasks are submitted simultaneously, as it can create an unbounded number of threads.

3.  **Scheduled Thread Pool (`Executors.newScheduledThreadPool(int corePoolSize)`)**
    *   **Behavior:** Creates a pool that can schedule commands to run after a given delay, or to execute periodically.
    *   **Methods:** `schedule()`, `scheduleAtFixedRate()`, `scheduleWithFixedDelay()`.
    *   **Use Case:** For tasks that need to be run at specific times or intervals, like background cleanup jobs or health checks.

##### **`Callable<V>` and `Future<V>`**

*   **`Runnable`'s Limitation:** The `run()` method is `void` and cannot throw checked exceptions.
*   **`Callable<V>`:** A task that can **return a result** and **throw a checked exception**. It has a single method: `V call() throws Exception`.
*   **`Future<V>`:** An object that represents the result of an asynchronous computation. When you `submit` a `Callable`, you get a `Future` back immediately. The `Future` acts as a placeholder for the result, which may not be available yet.
    *   **`V get()`:** This method **blocks** until the computation is complete and then retrieves its result.
    *   **`isDone()`:** Checks if the task has completed.
    *   **`cancel(boolean mayInterruptIfRunning)`:** Attempts to cancel the task.

---

#### **2. Example Code Snippet: Using a Fixed Thread Pool**

This example demonstrates submitting tasks to an `ExecutorService` and retrieving their results using `Future`.

```java
import java.util.concurrent.*;

// A task that returns a result and can throw an exception
class FactorialCalculator implements Callable<Long> {
    private final int number;

    public FactorialCalculator(int number) {
        if (number < 0) {
            throw new IllegalArgumentException("Number must be non-negative.");
        }
        this.number = number;
    }

    @Override
    public Long call() throws Exception {
        long result = 1;
        for (int i = 2; i <= number; i++) {
            result *= i;
            Thread.sleep(100); // Simulate a long computation
        }
        System.out.println("Factorial of " + number + " is " + result);
        return result;
    }
}

public class ExecutorServiceDemo {
    public static void main(String[] args) {
        // Create a pool with 2 threads
        ExecutorService executor = Executors.newFixedThreadPool(2);

        // Submit a task and get a Future back
        System.out.println("Submitting task for 10...");
        Future<Long> future10 = executor.submit(new FactorialCalculator(10));

        System.out.println("Submitting task for 5...");
        Future<Long> future5 = executor.submit(new FactorialCalculator(5));

        try {
            // The get() method blocks until the result is available.
            System.out.println("Waiting for result of 10...");
            long result10 = future10.get();
            System.out.println("Result of factorial(10) is: " + result10);

            System.out.println("Waiting for result of 5...");
            long result5 = future5.get();
            System.out.println("Result of factorial(5) is: " + result5);

        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        } finally {
            // Always shut down the executor service!
            executor.shutdown();
        }
    }
}
```

---

#### **3. Mini Exercise**

You are tasked with downloading the content of several URLs concurrently.
1.  Create a `Callable<String>` class named `UrlContentDownloader` that takes a URL string in its constructor.
2.  The `call()` method should simulate downloading by sleeping for a random duration and then returning a dummy string like "Content of [URL]".
3.  In `main`, create a `List<String>` of URLs.
4.  Create a fixed thread pool.
5.  Iterate through your URL list, create a `UrlContentDownloader` for each, and `submit` it to the executor, storing the returned `Future<String>` objects in a `List<Future<String>>`.
6.  After submitting all tasks, iterate through the list of `Future`s and call `get()` on each one to retrieve and print the content.
7.  Properly shut down the executor service in a `finally` block.

---

#### **4. Quiz Question**

**Question:** What is the primary difference between `executor.execute(Runnable)` and `executor.submit(Runnable)`?

A) `execute()` is for `Runnable`s, while `submit()` is only for `Callable`s.
B) `execute()` can throw exceptions, while `submit()` cannot.
C) `execute()` returns `void` ("fire and forget"), while `submit()` returns a `Future` object that can be used to track the task's completion and result.
D) `execute()` uses a fixed thread pool, while `submit()` uses a cached thread pool.

*(Scroll down for the answer)*

...

**Answer:** C) `execute()` returns `void` ("fire and forget"), while `submit()` returns a `Future` object that can be used to track the task's completion and result. Even when submitting a `Runnable`, `submit()` returns a `Future<?>` which can be used to check if the task is done or to cancel it. This makes `submit()` more powerful and generally preferred.

### **Lesson 6: Atomic Operations and the Locks Framework**

#### **1. Concept Explanation**

While `synchronized` is a powerful tool, it's a heavyweight, blocking mechanism. The `java.util.concurrent` package provides more sophisticated and fine-grained tools for managing thread safety: **atomic variables** for lock-free operations and the **Locks Framework** for advanced locking patterns.

##### **Atomic Variables and CAS (Compare-And-Swap)**

The `java.util.concurrent.atomic` package provides a set of classes (`AtomicInteger`, `AtomicLong`, `AtomicReference`, `AtomicBoolean`) that support lock-free, thread-safe programming on single variables.

*   **The Problem with `volatile`:** A `volatile int count;` with a `count++` operation is not thread-safe. `volatile` guarantees visibility, but `count++` is not an atomic operation.
*   **The Solution with `AtomicInteger`:** An `AtomicInteger` wraps an `int` value and provides atomic compound operations like `incrementAndGet()`, `getAndAdd()`, and `compareAndSet()`.

**Internal Mechanism: Compare-And-Swap (CAS)**
Atomic variables achieve their thread safety without using locks. Instead, they rely on a low-level, hardware-supported atomic instruction called **Compare-And-Swap (CAS)**. A CAS operation is an optimistic approach that involves three operands:
1.  **V:** The memory location to be modified (the variable).
2.  **A:** The "expected" old value that the thread thinks is in V.
3.  **B:** The new value to be set.

The CAS instruction will atomically update the value at V to B **if and only if** the current value at V is equal to A. The instruction returns a boolean indicating whether the update was successful.

**Analogy:** Imagine a silent auction. You want to bid $110. You write on your slip: "If the current bid is $100 (A), my new bid is $110 (B)." You give this to the auctioneer.
*   **Success:** If the current bid is still $100 when the auctioneer reads your slip, they update the price to $110. Your operation succeeded.
*   **Failure:** If another bidder was faster and the price is already $120, your condition ("if the current bid is $100") is false. The auctioneer rejects your slip. Your operation failed. You must now get the new current price ($120) and submit a new bid.

Methods like `incrementAndGet()` in `AtomicInteger` typically use CAS in a loop:
```java
// Conceptual logic of incrementAndGet()
int current;
do {
    current = get(); // Read the current value
} while (!compareAndSet(current, current + 1)); // Try to swap it with the incremented value
// If another thread changed 'current' in the meantime, compareAndSet fails, and we loop to try again.
```
This is a **non-blocking** or **lock-free** approach, which can offer significantly better performance under high contention than traditional locks.

##### **The `java.util.concurrent.locks` Framework**

The `Lock` interface provides a more flexible and powerful locking mechanism than the `synchronized` keyword.

**`ReentrantLock`**
A `ReentrantLock` is a direct replacement for `synchronized` that offers more features.

| Feature | `synchronized` Keyword | `ReentrantLock` |
| :--- | :--- | :--- |
| **Acquisition** | Blocks indefinitely. | Can block (`lock()`), but also supports non-blocking `tryLock()` and timed `tryLock(time, unit)`. |
| **Interruptibility**| A thread cannot be interrupted while waiting for a lock. | A thread can be interrupted while waiting for a lock via `lockInterruptibly()`. |
| **Fairness** | Unfair by default (no guarantee of acquisition order). | Can be configured as "fair" or "unfair" in the constructor. A fair lock grants access to the longest-waiting thread. |
| **Unlocking** | Automatic (when the block/method is exited). | **Manual**. You **must** call `unlock()` in a `finally` block to guarantee the lock is released. |

**The Mandatory `try-finally` Pattern for Locks:**
```java
Lock myLock = new ReentrantLock();
...
myLock.lock(); // Acquire the lock
try {
    // ... critical section ...
} finally {
    myLock.unlock(); // MUST be in a finally block
}
```

**`ReadWriteLock` and `ReentrantReadWriteLock`**
This lock maintains a pair of associated locks, one for reading and one for writing. It's designed to solve a common problem: if a shared resource is read much more often than it is written, using a single exclusive lock (`synchronized` or `ReentrantLock`) is inefficient because it prevents multiple readers from accessing the resource at the same time.

*   **The Rule:** Multiple threads can hold the **read lock** simultaneously, as long as no thread holds the **write lock**. Only one thread can hold the **write lock** at a time, and it excludes all readers.
*   **Use Case:** Perfect for caching systems, configuration objects, or any data structure that is read frequently but modified infrequently.

---

#### **2. Example Code Snippet**

This example shows a thread-safe counter implemented with `AtomicInteger` and a thread-safe cache implemented with `ReentrantReadWriteLock`.

```java
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

// 1. Counter using AtomicInteger (lock-free)
class AtomicCounter {
    private AtomicInteger count = new AtomicInteger(0);

    public void increment() {
        count.incrementAndGet(); // Atomic operation
    }

    public int getCount() {
        return count.get();
    }
}

// 2. Cache using ReadWriteLock
class ThreadSafeCache<K, V> {
    private final Map<K, V> map = new HashMap<>();
    private final ReadWriteLock lock = new ReentrantReadWriteLock();
    private final Lock readLock = lock.readLock();
    private final Lock writeLock = lock.writeLock();

    public V get(K key) {
        readLock.lock(); // Multiple threads can acquire the read lock
        try {
            return map.get(key);
        } finally {
            readLock.unlock();
        }
    }

    public void put(K key, V value) {
        writeLock.lock(); // Only one thread can acquire the write lock
        try {
            map.put(key, value);
        } finally {
            writeLock.unlock();
        }
    }
}
```

---

#### **3. Mini Exercise**

Refactor the `BankAccount` class from Lesson 2.
1.  Instead of using `synchronized` methods, give the `BankAccount` a `private final ReentrantLock lock` field.
2.  Modify the `deposit(double amount)` and `withdraw(double amount)` methods.
3.  Inside each method, acquire the lock using `lock.lock()`.
4.  Place the logic that modifies the `balance` inside a `try` block.
5.  Ensure that `lock.unlock()` is called in a corresponding `finally` block to guarantee the lock is always released.

---

#### **4. Quiz Question**

**Question:** Which of the following is a capability of `ReentrantLock` that is **not** available when using a `synchronized` block?

A) It is reentrant, allowing a thread to acquire a lock it already holds.
B) It provides a happens-before relationship, ensuring memory visibility.
C) It allows a thread to attempt to acquire a lock for a specified amount of time and give up if it's not available.
D) It can be used to protect static methods.

*(Scroll down for the answer)*

...

**Answer:** C) It allows a thread to attempt to acquire a lock for a specified amount of time and give up if it's not available. This is accomplished using the `tryLock(long time, TimeUnit unit)` method. `synchronized` blocks will wait indefinitely to acquire a lock. Both are reentrant (A) and provide happens-before guarantees (B). Both can be used to protect static members (C, by using a static lock object).

### **Lesson 6: Atomic Operations and the Locks Framework**

#### **1. Concept Explanation**

While `synchronized` is a powerful tool, it's a heavyweight, blocking mechanism. The `java.util.concurrent` package provides more sophisticated and fine-grained tools for managing thread safety: **atomic variables** for lock-free operations and the **Locks Framework** for advanced locking patterns.

##### **Atomic Variables and CAS (Compare-And-Swap)**

The `java.util.concurrent.atomic` package provides a set of classes (`AtomicInteger`, `AtomicLong`, `AtomicReference`, `AtomicBoolean`) that support lock-free, thread-safe programming on single variables.

*   **The Problem with `volatile`:** A `volatile int count;` with a `count++` operation is not thread-safe. `volatile` guarantees visibility, but `count++` is not an atomic operation.
*   **The Solution with `AtomicInteger`:** An `AtomicInteger` wraps an `int` value and provides atomic compound operations like `incrementAndGet()`, `getAndAdd()`, and `compareAndSet()`.

**Internal Mechanism: Compare-And-Swap (CAS)**
Atomic variables achieve their thread safety without using locks. Instead, they rely on a low-level, hardware-supported atomic instruction called **Compare-And-Swap (CAS)**. A CAS operation is an optimistic approach that involves three operands:
1.  **V:** The memory location to be modified (the variable).
2.  **A:** The "expected" old value that the thread thinks is in V.
3.  **B:** The new value to be set.

The CAS instruction will atomically update the value at V to B **if and only if** the current value at V is equal to A. The instruction returns a boolean indicating whether the update was successful.

**Analogy:** Imagine a silent auction. You want to bid $110. You write on your slip: "If the current bid is $100 (A), my new bid is $110 (B)." You give this to the auctioneer.
*   **Success:** If the current bid is still $100 when the auctioneer reads your slip, they update the price to $110. Your operation succeeded.
*   **Failure:** If another bidder was faster and the price is already $120, your condition ("if the current bid is $100") is false. The auctioneer rejects your slip. Your operation failed. You must now get the new current price ($120) and submit a new bid.

Methods like `incrementAndGet()` in `AtomicInteger` typically use CAS in a loop:
```java
// Conceptual logic of incrementAndGet()
int current;
do {
    current = get(); // Read the current value
} while (!compareAndSet(current, current + 1)); // Try to swap it with the incremented value
// If another thread changed 'current' in the meantime, compareAndSet fails, and we loop to try again.
```
This is a **non-blocking** or **lock-free** approach, which can offer significantly better performance under high contention than traditional locks.

##### **The `java.util.concurrent.locks` Framework**

The `Lock` interface provides a more flexible and powerful locking mechanism than the `synchronized` keyword.

**`ReentrantLock`**
A `ReentrantLock` is a direct replacement for `synchronized` that offers more features.

| Feature | `synchronized` Keyword | `ReentrantLock` |
| :--- | :--- | :--- |
| **Acquisition** | Blocks indefinitely. | Can block (`lock()`), but also supports non-blocking `tryLock()` and timed `tryLock(time, unit)`. |
| **Interruptibility**| A thread cannot be interrupted while waiting for a lock. | A thread can be interrupted while waiting for a lock via `lockInterruptibly()`. |
| **Fairness** | Unfair by default (no guarantee of acquisition order). | Can be configured as "fair" or "unfair" in the constructor. A fair lock grants access to the longest-waiting thread. |
| **Unlocking** | Automatic (when the block/method is exited). | **Manual**. You **must** call `unlock()` in a `finally` block to guarantee the lock is released. |

**The Mandatory `try-finally` Pattern for Locks:**
```java
Lock myLock = new ReentrantLock();
...
myLock.lock(); // Acquire the lock
try {
    // ... critical section ...
} finally {
    myLock.unlock(); // MUST be in a finally block
}
```

**`ReadWriteLock` and `ReentrantReadWriteLock`**
This lock maintains a pair of associated locks, one for reading and one for writing. It's designed to solve a common problem: if a shared resource is read much more often than it is written, using a single exclusive lock (`synchronized` or `ReentrantLock`) is inefficient because it prevents multiple readers from accessing the resource at the same time.

*   **The Rule:** Multiple threads can hold the **read lock** simultaneously, as long as no thread holds the **write lock**. Only one thread can hold the **write lock** at a time, and it excludes all readers.
*   **Use Case:** Perfect for caching systems, configuration objects, or any data structure that is read frequently but modified infrequently.

---

#### **2. Example Code Snippet**

This example shows a thread-safe counter implemented with `AtomicInteger` and a thread-safe cache implemented with `ReentrantReadWriteLock`.

```java
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;

// 1. Counter using AtomicInteger (lock-free)
class AtomicCounter {
    private AtomicInteger count = new AtomicInteger(0);

    public void increment() {
        count.incrementAndGet(); // Atomic operation
    }

    public int getCount() {
        return count.get();
    }
}

// 2. Cache using ReadWriteLock
class ThreadSafeCache<K, V> {
    private final Map<K, V> map = new HashMap<>();
    private final ReadWriteLock lock = new ReentrantReadWriteLock();
    private final Lock readLock = lock.readLock();
    private final Lock writeLock = lock.writeLock();

    public V get(K key) {
        readLock.lock(); // Multiple threads can acquire the read lock
        try {
            return map.get(key);
        } finally {
            readLock.unlock();
        }
    }

    public void put(K key, V value) {
        writeLock.lock(); // Only one thread can acquire the write lock
        try {
            map.put(key, value);
        } finally {
            writeLock.unlock();
        }
    }
}
```

---

#### **3. Mini Exercise**

Refactor the `BankAccount` class from Lesson 2.
1.  Instead of using `synchronized` methods, give the `BankAccount` a `private final ReentrantLock lock` field.
2.  Modify the `deposit(double amount)` and `withdraw(double amount)` methods.
3.  Inside each method, acquire the lock using `lock.lock()`.
4.  Place the logic that modifies the `balance` inside a `try` block.
5.  Ensure that `lock.unlock()` is called in a corresponding `finally` block to guarantee the lock is always released.

---

#### **4. Quiz Question**

**Question:** Which of the following is a capability of `ReentrantLock` that is **not** available when using a `synchronized` block?

A) It is reentrant, allowing a thread to acquire a lock it already holds.
B) It provides a happens-before relationship, ensuring memory visibility.
C) It allows a thread to attempt to acquire a lock for a specified amount of time and give up if it's not available.
D) It can be used to protect static methods.

*(Scroll down for the answer)*

...

**Answer:** C) It allows a thread to attempt to acquire a lock for a specified amount of time and give up if it's not available. This is accomplished using the `tryLock(long time, TimeUnit unit)` method. `synchronized` blocks will wait indefinitely to acquire a lock. Both are reentrant (A) and provide happens-before guarantees (B). Both can be used to protect static members (C, by using a static lock object).

### **Lesson 8: Fork/Join Framework and Parallelism**

#### **1. Concept Explanation**

##### **Concurrency vs. Parallelism**
These two terms are often used interchangeably, but they represent different concepts.
*   **Concurrency:** Is about dealing with many tasks at once by interleaving their execution. It's about structuring a program to handle multiple, independent tasks. A single-core CPU can achieve concurrency by rapidly switching between threads (context switching).
*   **Parallelism:** Is about doing many tasks at once. It requires hardware with multiple processing units (e.g., a multi-core CPU). Parallelism is a subset of concurrency where the interleaved tasks are actually executing simultaneously.

**Analogy:**
*   **Concurrency:** A single chef in a kitchen is cooking two dishes. They chop vegetables for dish A, then put a pot on the stove for dish B, then go back to dish A, etc. They are *managing* two tasks at once, but only *doing* one thing at any given microsecond.
*   **Parallelism:** Two chefs in the same kitchen. One chef is dedicated to dish A, and the other is dedicated to dish B. They are both working *simultaneously*.

The **Fork/Join Framework**, introduced in Java 7, is a tool designed specifically for achieving **parallelism**.

##### **The Fork/Join Framework**
This framework is an implementation of the `ExecutorService` designed to efficiently run a large number of tasks using a pool of worker threads. It is specifically built for **"divide and conquer"** algorithms. The core idea is to take a large problem, recursively break it down into smaller, independent subproblems until they are simple enough to be solved directly, and then combine the results of the subproblems to get the final solution.

It is best suited for **CPU-bound tasks**, not I/O-bound tasks where threads would be idle waiting.

##### **Core Components**
1.  **`ForkJoinPool`:**
    *   This is the thread pool that manages the worker threads and executes the tasks.
    *   **Work-Stealing Algorithm:** This is the key to its efficiency. Each worker thread in the pool has its own double-ended queue (deque) of tasks. A thread processes tasks from the head of its own deque. When a thread's own deque is empty, it becomes idle. Instead of sleeping, it looks at the **tail** of another busy thread's deque and "steals" a task to execute. This ensures that all threads are kept busy, maximizing CPU utilization.

2.  **`RecursiveTask<V>`:**
    *   A task that returns a result. You extend this class and implement its `compute()` method. This is the most common base class.

3.  **`RecursiveAction`:**
    *   A task that does not return a result (its `compute()` method is `void`).

##### **The "Fork" and "Join" Steps**
The logic inside the `compute()` method typically follows this pattern:
1.  **Base Case:** Check if the current chunk of work is small enough to be solved directly without further splitting.
2.  **Recursive Step (Fork):** If the work is too large, "fork" it by splitting it into two or more subtasks.
3.  **Execute Subtasks:** Start the subtasks for asynchronous execution.
4.  **Combine Results (Join):** Wait for the subtasks to complete and then combine their results.

---

#### **2. Example Code Snippet: Parallel Summation**

This example uses the Fork/Join framework to calculate the sum of all elements in a large array in parallel.

```java
import java.util.concurrent.ForkJoinPool;
import java.util.concurrent.RecursiveTask;

// A task that returns a Long result
class ArraySumTask extends RecursiveTask<Long> {
    // A problem size threshold below which we don't split further.
    private static final int THRESHOLD = 10_000;
    private final long[] array;
    private final int start;
    private final int end;

    public ArraySumTask(long[] array, int start, int end) {
        this.array = array;
        this.start = start;
        this.end = end;
    }

    @Override
    protected Long compute() {
        int length = end - start;
        // 1. Base Case: If the task is small enough, compute directly.
        if (length <= THRESHOLD) {
            long sum = 0;
            for (int i = start; i < end; i++) {
                sum += array[i];
            }
            return sum;
        }

        // 2. Recursive Step: The task is too large, so split it.
        int mid = start + (length / 2);
        ArraySumTask leftTask = new ArraySumTask(array, start, mid);
        ArraySumTask rightTask = new ArraySumTask(array, mid, end);

        // 3. Fork: Asynchronously execute the left subtask.
        leftTask.fork();

        // Compute the right subtask synchronously on the current thread.
        // This is a common optimization to reduce thread management overhead.
        long rightResult = rightTask.compute();

        // 4. Join: Wait for the left subtask to complete and get its result.
        long leftResult = leftTask.join();

        // 5. Combine the results.
        return leftResult + rightResult;
    }
}

public class ForkJoinDemo {
    public static void main(String[] args) {
        long[] numbers = new long[1_000_000];
        for (int i = 0; i < numbers.length; i++) {
            numbers[i] = i + 1;
        }

        // Use the common pool, which is a static, shared pool.
        ForkJoinPool pool = ForkJoinPool.commonPool();
        
        // Create the main task
        ArraySumTask task = new ArraySumTask(numbers, 0, numbers.length);

        // Submit the task to the pool and get the result
        long result = pool.invoke(task);

        System.out.println("Sum calculated in parallel: " + result);
        
        // The common pool should not be shut down.
    }
}
```

---

#### **3. Mini Exercise**

You need to find the largest number in a very large array of integers using the Fork/Join framework.
1.  Create a class `MaxFinderTask` that extends `RecursiveTask<Integer>`.
2.  The `compute()` method should have a base case: if the size of the array segment is below a threshold, find the maximum number using a simple loop.
3.  In the recursive step, split the task in two.
4.  Fork the left subtask, compute the right subtask, and join the left subtask.
5.  The "combine results" step will be to return `Math.max()` of the results from the left and right subtasks.
6.  In `main`, create a large array of random integers and use a `ForkJoinPool` to find and print the maximum value.

---

#### **4. Quiz Question**

**Question:** What is the primary advantage of the work-stealing algorithm used by the `ForkJoinPool`?

A) It guarantees that smaller tasks are always executed before larger tasks.
B) It minimizes memory usage by reusing `RecursiveTask` objects.
C) It maximizes CPU utilization by ensuring that worker threads that become idle take tasks from other, busy threads.
D) It simplifies the code by automatically combining the results of subtasks.

*(Scroll down for the answer)*

...

**Answer:** C) It maximizes CPU utilization by ensuring that worker threads that become idle take tasks from other, busy threads. The core purpose of work-stealing is to keep all available CPU cores busy, preventing threads from sitting idle while there is still work to be done elsewhere in the pool. This leads to higher throughput for parallel computations.

### **Lesson 9: Virtual Threads (Java 21+)**

#### **1. Concept Explanation**

##### **The Problem with Traditional ("Platform") Threads**
As we've seen, traditional Java threads (`java.lang.Thread`) are "platform threads." Each platform thread is a thin wrapper around a heavy operating system (OS) thread.
*   **Heavyweight:** OS threads are a scarce resource. They consume a significant amount of memory (typically 1-2 MB for the stack) and have a high context-switching overhead.
*   **The Scalability Bottleneck:** This scarcity creates a fundamental limit on scalability, especially for applications with a **thread-per-request** model (common in web servers). If each of the 100,000 concurrent user requests gets its own platform thread, the server will quickly run out of memory and crash. This is why complex, asynchronous programming models (like NIO with selectors or reactive frameworks) were invented—to manage many tasks with few OS threads.

##### **The Solution: Virtual Threads (Project Loom)**
**Virtual threads**, introduced as a final feature in Java 21, are a revolutionary solution to this problem.

*   **What are they?** Virtual threads are **lightweight threads managed by the Java runtime (JVM)**, not directly by the OS. Many virtual threads run their Java code on the *same* OS thread.
*   **The Key Idea:** When a virtual thread executes code that would block on an I/O operation (e.g., reading from a network socket), it does **not** block the underlying OS thread. Instead, the JVM **unmounts** the virtual thread from its OS thread (the "carrier" thread) and makes the OS thread available to run another virtual thread. When the I/O operation is complete, the JVM **mounts** the virtual thread back onto an available carrier thread to continue its execution.

**Analogy:**
*   **Platform Threads:** A fleet of delivery trucks (OS threads). Each truck can only handle one delivery at a time. If a delivery requires waiting at a warehouse, the entire truck is stuck and unusable for other deliveries.
*   **Virtual Threads:** A large team of delivery drivers (virtual threads) and a small, shared fleet of trucks (the "carrier" OS threads). When a driver arrives at a warehouse to wait for a package, they get out of the truck, and another driver immediately takes that truck to make another delivery. The waiting driver doesn't hold the truck hostage. When their package is ready, they are assigned the next available truck.

##### **Differences: Platform vs. Virtual Threads**

| Feature | Platform Threads | Virtual Threads |
| :--- | :--- | :--- |
| **Mapping** | 1-to-1 mapping with an OS thread. | Many-to-1 mapping with an OS thread. |
| **Weight** | Heavyweight (scarce, high memory footprint). | Lightweight (can have millions, very low memory footprint). |
| **Management**| Managed by the Operating System. | Managed by the Java Virtual Machine (JVM). |
| **Blocking** | Blocking I/O blocks the OS thread. | Blocking I/O **does not** block the OS thread (it unmounts). |
| **Creation** | Relatively slow and expensive. | Extremely fast and cheap. |
| **Pooling** | **Pooling is essential** to manage the scarce resource. | **Pooling is an anti-pattern.** You should create a new virtual thread for every task. |

##### **How to Use Virtual Threads**
The API is designed to be incredibly simple and familiar.
1.  **`Thread.startVirtualThread(Runnable)`:** A static factory method to create and start a virtual thread for a given task.
2.  **`Executors.newVirtualThreadPerTaskExecutor()`:** The preferred way. This creates an `ExecutorService` that creates a new virtual thread for each submitted task. It does not pool them.

**Impact on Code:** The most significant benefit of virtual threads is that they allow you to write simple, synchronous, blocking I/O code (the "thread-per-request" style) that is easy to read, write, and debug, but which scales like complex asynchronous code.

---

#### **2. Example Code Snippet**

This example simulates making thousands of concurrent network calls, a task that would be impossible with platform threads but is trivial with virtual threads.

```java
import java.time.Duration;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.stream.IntStream;

public class VirtualThreadsDemo {
    public static void main(String[] args) {
        long startTime = System.currentTimeMillis();

        // The modern, preferred way to use virtual threads.
        // This executor creates a new virtual thread for each of the 100,000 tasks.
        try (ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor()) {

            IntStream.range(0, 100_000).forEach(i -> {
                executor.submit(() -> {
                    // Simulate a blocking I/O operation (e.g., a network call)
                    try {
                        Thread.sleep(Duration.ofSeconds(1));
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                    }
                    // System.out.println("Task " + i + " completed.");
                });
            });

        } // The executor is automatically shut down and waits for tasks to complete.

        long endTime = System.currentTimeMillis();
        System.out.printf("Processed 100,000 tasks in %d ms\n", (endTime - startTime));
        // This will complete in just over 1 second, not 100,000 seconds,
        // because all tasks run concurrently without consuming thousands of OS threads.
    }
}
```

---

#### **3. Mini Exercise**

Refactor the URL downloader exercise from Lesson 5 to use virtual threads.
1.  Take the `UrlContentDownloader` `Callable` from the previous exercise.
2.  Instead of using `Executors.newFixedThreadPool()`, use `Executors.newVirtualThreadPerTaskExecutor()`.
3.  Increase the number of URLs in your list to 1,000.
4.  Run the program and observe how it handles this large number of concurrent (simulated) blocking tasks without any issues. Notice that you don't need to manage a pool size; the executor handles it for you.

---

#### **4. Quiz Question**

**Question:** What is the most significant benefit of using virtual threads?

A) They make CPU-bound computations run faster than platform threads.
B) They allow you to write simple, blocking I/O code that scales to handle a very large number of concurrent connections.
C) They completely eliminate the need for synchronization primitives like `synchronized` and `ReentrantLock`.
D) They consume no memory, unlike platform threads which have a large stack.

*(Scroll down for the answer)*

...

**Answer:** B) They allow you to write simple, blocking I/O code that scales to handle a very large number of concurrent connections. Virtual threads do not make CPU-bound code faster (that's the job of parallelism with the Fork/Join framework). They do not eliminate the need for synchronization when accessing shared mutable state. While they are very lightweight, they do consume a small amount of memory. Their primary purpose is to dramatically improve the scalability of applications that are dominated by blocking I/O operations.

### **Lesson 10: Topic Summary, Interview Questions, and Final Project**

This final lesson provides a comprehensive summary of the key concepts in Java multithreading and concurrency, presents common interview questions to solidify your knowledge, and offers a practical mini-project to apply these principles.

---

#### **1. Summary Table of Key Concepts**

| Concept | Description & Key Takeaway |
| :--- | :--- |
| **Thread Lifecycle** | `NEW` → `RUNNABLE` ↔ `BLOCKED` / `WAITING` / `TIMED_WAITING` → `TERMINATED`. Understanding these states is crucial for debugging. |
| **Race Condition** | A bug caused by unpredictable timing of threads accessing **shared mutable state**. Solved by synchronization. |
| **`synchronized`** | Provides **atomicity** and **visibility**. Uses an object's intrinsic lock for mutual exclusion. Reentrant. |
| **`volatile`** | Provides **visibility** and **ordering** guarantees, but **not atomicity**. Use for simple flags, not compound operations like `count++`. |
| **Java Memory Model** | Defines the "happens-before" relationship, guaranteeing when writes by one thread are visible to others. `synchronized`, `volatile`, and `final` create memory barriers. |
| **`wait`/`notifyAll`** | Classic mechanism for thread coordination. `wait()` releases the lock and pauses. `notifyAll()` wakes up waiting threads. **Must be used in a `synchronized` block and a `while` loop.** |
| **Executor Framework** | Decouples task submission from execution. **Use thread pools instead of `new Thread()`**. `ExecutorService` is the main interface. `Callable` returns a result via a `Future`. |
| **Concurrent Collections**| `ConcurrentHashMap`, `CopyOnWriteArrayList`, `BlockingQueue`. High-performance, thread-safe collections from `java.util.concurrent`. |
| **Locks Framework** | `ReentrantLock` is a more flexible alternative to `synchronized`. `ReadWriteLock` allows multiple concurrent readers. **Must use a `try-finally` block for `unlock()`**. |
| **Atomic Variables** | `AtomicInteger`, `AtomicReference`, etc. Provide lock-free, thread-safe operations on single variables using the **Compare-And-Swap (CAS)** mechanism. |
| **Concurrency Utilities**| **`CountDownLatch`**: Wait for N events to complete. **`CyclicBarrier`**: Wait for N threads to reach a common point. **`Semaphore`**: Limit access to a resource. |
| **Fork/Join Framework**| `ExecutorService` for **parallelism**. Uses a **work-stealing** algorithm for CPU-bound, "divide and conquer" tasks. |
| **Virtual Threads** | Lightweight, JVM-managed threads. Ideal for I/O-bound tasks. Allows writing simple, blocking code that scales to millions of concurrent operations without pooling. |
| **Deadlock** | A situation where two or more threads are blocked forever, each waiting for a lock held by the other. Avoid by acquiring locks in a consistent global order. |

---

#### **2. Common Interview Questions**

1.  **"What is the difference between concurrency and parallelism?"**
    *   *Answer:* Concurrency is about *dealing* with multiple tasks at once by interleaving execution, which can be done on a single CPU core. Parallelism is about *doing* multiple tasks at once, which requires multiple CPU cores. Parallelism is a form of concurrency.

2.  **"Explain the difference between `synchronized` and `volatile`."**
    *   *Answer:* `synchronized` provides both mutual exclusion (atomicity) and memory visibility. It is used to protect compound actions. `volatile` only provides memory visibility and ordering guarantees; it does not provide atomicity. It is suitable for simple flags or variables where writes and reads are atomic by themselves.

3.  **"Why must `wait()` and `notify()` be called from a `synchronized` block?"**
    *   *Answer:* They must be called from a `synchronized` block to avoid race conditions. A thread must own the object's monitor lock to ensure that the condition it is about to wait for doesn't change between the time it checks the condition and the time it goes to sleep. The `wait()` call atomically releases this lock, preventing deadlocks.

4.  **"What is a `Future` and how is it used?"**
    *   *Answer:* A `Future` is a placeholder for the result of an asynchronous computation. When you submit a `Callable` to an `ExecutorService`, you immediately get a `Future` back. Your code can continue to do other work. When you need the result, you call `future.get()`, which will block until the computation is complete and the result is available.

5.  **"When should you use a platform thread versus a virtual thread?"**
    *   *Answer:* Use platform threads for a small number of long-running, CPU-intensive tasks where you want a one-to-one mapping with an OS thread (e.g., using a fixed thread pool sized to the number of CPU cores). Use virtual threads for a large number of I/O-bound or blocking tasks. For virtual threads, you should not pool them; create a new one for each task.

6.  **"How would you prevent a deadlock?"**
    *   *Answer:* The most common way is to enforce a strict, global ordering for lock acquisition. If all threads always acquire lock A before acquiring lock B, a deadlock where one thread has A and waits for B, while another has B and waits for A, becomes impossible. Other strategies include using `tryLock` with a timeout or designing the system to avoid nested locks.

---

#### **3. Final Mini-Project: Concurrent Web Crawler**

This project will combine many of the concepts we've learned—`ExecutorService`, `Future`, `ConcurrentHashMap`, and thread safety—to build a simple web crawler that can fetch multiple pages concurrently.

**🎯 Goal:** Create a program that starts from a single URL, finds all the links on that page, and then concurrently "crawls" those links to a specified depth.

**Project Requirements:**

1.  **`WebPageFetcher` Class:**
    *   Create a simple helper class or method `String fetch(String url)`.
    *   This method will simulate fetching the content of a URL. It should `Thread.sleep()` for a random duration to simulate a blocking network call.
    *   For this project, it can just return a dummy `String` that contains a few fake links. For example, if you fetch `"http://example.com"`, it might return `"<html>...<a href='http://example.com/page1'>...<a href='http://example.com/page2'>...</html>"`.

2.  **`ConcurrentCrawler` Class:**
    *   **ExecutorService:** The crawler should use an `ExecutorService` to manage the fetching tasks. Since this is an I/O-bound task, what is a good choice for the executor? A **virtual thread executor (`Executors.newVirtualThreadPerTaskExecutor()`)** is the perfect modern choice. A cached thread pool would be the traditional choice.
    *   **Visited Links:** The crawler needs to keep track of the URLs it has already visited to avoid getting stuck in loops and re-processing the same page. What is the best data structure for this? A thread-safe `Set`, which can be created from a **`ConcurrentHashMap.newKeySet()`**.
    *   **Recursive Crawling Logic:**
        *   The main method should be `crawl(String startUrl, int depth)`.
        *   This method should submit the initial URL as a task to the executor.
        *   You will need a recursive helper method that represents the task for a single URL. This method should:
            1.  Check if the URL has already been visited or if the max depth has been reached. If so, return.
            2.  Add the URL to the visited set.
            3.  "Fetch" the page content.
            4.  Parse the content to find all the links.
            5.  For each new link found, recursively submit a new crawl task to the executor for that link with `depth - 1`.

3.  **Main Class:**
    *   The `main` method should create an instance of `ConcurrentCrawler`.
    *   Call the `crawl()` method with a starting URL and a depth (e.g., 2).
    *   Properly shut down the `ExecutorService` and wait for all the crawling tasks to complete using `awaitTermination()`.
    *   Print a final message with the total number of unique pages visited.

This project will challenge you to manage asynchronous tasks, handle shared state (`visited` set) in a thread-safe manner, and structure a recursive, concurrent algorithm.
